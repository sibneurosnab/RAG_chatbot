# 6. Схема базы данных, индексы и SQL-функции

> В этом разделе описана структура **базы данных Supabase**, используемой системой: какие таблицы хранят информацию, как настроен индекс для быстрого поиска по эмбеддингам, и какие **SQL-функции (RPC)** реализованы для интеграции с workflow. База данных построена на PostgreSQL (Supabase) с расширением **pgvector** для хранения и поиска векторов.

## 6.1 Таблица `documents_paragraphs` – хранилище эмбеддингов документов

Главная таблица базы знаний – **`documents_paragraphs`** – содержит размеченный контент (чанки текста) из всех загруженных источников вместе с соответствующими эмбеддингами. Каждый добавленный документ (веб-страница, видео или файл) разбивается на несколько абзацев/предложений, которые сохраняются отдельными записями. Такая **унифицированная структура хранения** позволяет выполнять единый поиск по всему корпусу знаний.

**Основные поля таблицы:**

- `id` – первичный ключ (уникальный идентификатор фрагмента).
- `type` – тип источника: `"web"`, `"video"` или `"file"` (используется для указания происхождения чанка).
- `title` – заголовок документа (для веб-страниц) или название файла (для файлов), помогает при цитировании источника.
- `url` – URL источника (если тип `web` или `video`; для видео здесь хранится ссылка на YouTube).
- `file_name` – имя загруженного файла (если тип `file`; содержит оригинальное название документа).
- `paragraph_text` – собственно текст содержимого чанка.
- `paragraph_idx` – порядковый номер чанка в пределах исходного документа (начиная с 0). 
- `language` – язык текста чанка (двухбуквенный код, например `en` или `ru`, определяется на этапе очистки).
- `embedding` – векторное представление этого чанка размерностью 768 (тип данных – `vector(768)` из pgvector).
- `retrieved_at` – временная метка времени индексации (когда фрагмент был добавлен в базу).

Дополнительно, для обеспечения **идемпотентности** загрузки, введены поля:
- `batch_id` — уникальный идентификатор одной «партии» документов, которую обрабатывает ingest-workflow (один запуск = один `batch_id`).
- `idx_in_batch` — порядковый номер элемента внутри этой партии (0, 1, 2 …).

Комбинация **`(batch_id, idx_in_batch)` объявлена `UNIQUE` в DDL** (см. `supabase/01_schema.sql`). Это гарантирует, что при повторном запуске конвейера с тем же `batch_id` дубликаты не попадут в таблицу: попытка повторной вставки строки с тем же ключом будет проигнорирована. Поле `paragraph_idx`, в свою очередь, **не участвует** в уникальном ограничении — оно отражает позицию чанка внутри исходного документа после позднего разбиения и может повторяться для разных документов.

**Обновлённый список полей**

- `id` – первичный ключ (уникальный идентификатор фрагмента).
- `type` – тип источника: `"web"`, `"video"` или `"file"` (используется для указания происхождения чанка).
- `title` – заголовок документа (для веб-страниц) или название файла (для файлов), помогает при цитировании источника.
- `url` – URL источника (если тип `web` или `video`; для видео здесь хранится ссылка на YouTube).
- `file_name` – имя загруженного файла (если тип `file`; содержит оригинальное название документа).
- `paragraph_text` – собственно текст содержимого чанка.
- `paragraph_idx` – порядковый номер чанка в пределах исходного документа (начиная с 0). 
- `language` – язык текста чанка (двухбуквенный код, например `en` или `ru`, определяется на этапе очистки).
- `embedding` – векторное представление этого чанка размерностью 768 (тип данных – `vector(768)` из pgvector).
- `retrieved_at` – временная метка времени индексации (когда фрагмент был добавлен в базу).
- `batch_id` – идентификатор партии загрузки.
- `idx_in_batch` – порядковый номер элемента в партии.

**Назначение `documents_paragraphs`:** эта таблица служит «векторным хранилищем знаний» системы. Именно в ней выполняется поиск фрагментов по семантическому сходству: RAG-поиск обращается к `documents_paragraphs` и находит релевантные части документов по близости эмбеддингов.

## 6.2 Таблица `chat_messages` – история диалога

Для поддержки режима чата система сохраняет **историю переписки** с каждым пользователем. Таблица **`chat_messages`** хранит все сообщения, которыми обменялись пользователь и бот, и используется при формировании контекста диалога.

**Структура `chat_messages`:**

- `id` – уникальный ID сообщения (первичный ключ, генерируется автоматически).
- `user_id` – идентификатор пользователя Telegram (числовой ID чата), которому принадлежит это сообщение.
- `role` – роль отправителя: `"user"` для сообщений от пользователя, `"assistant"` для ответов бота.
- `message` – текст самого сообщения.
- `created_at` – временная метка (тип `timestamptz`), когда сообщение было отправлено/получено.

Эта таблица пополняется по мере общения: перед отправкой ответа бот записывает в неё **две записи** – сначала вопрос пользователя, затем сгенерированный ответ ассистента (формируя пару). Хранение истории в БД позволяет затем быстро выбирать последние *N* сообщений для контекста. Например, при каждом новом вопросе **workflow** считывает последние сообщения данного пользователя из `chat_messages` (сортируя по времени) и объединяет их в одну строку – таким образом собирается «контекст предыдущего диалога». LLM получает эту историю в системном сообщении, чтобы сохранять преемственность ответа.

**Ограничение длины истории:** чтобы база не росла бесконечно и чтобы не пересылать модели чрезмерно большой контекст, реализован механизм ограничения длины диалога. Он задаётся параметром, определяющим сколько сохраняется **пар сообщений** (вопрос+ответ) для каждого пользователя. Например, если указано хранить последние N пар, то при добавлении новой пара старых сообщений, превышающих этот лимит, будет автоматически удалена. Такой **тримминг диалога** выполняется на уровне базы данных с помощью специальной функции (см. `insert_and_trim_pairs` в разделе 6.5.2), которая удаляет самые старые записи, оставляя только N последних пар.

## 6.3 Таблица `user_state` – хранение режима работы пользователя

Взаимодействие с ботом предусматривает переключение режимов – например, **режим "Чат"** (общение с ботом на основе уже загруженных знаний) и **режим "База"** (добавление новых документов в базу знаний). Эти режимы задают различное поведение workflow. Таблица **`user_state`** хранит текущий режим для каждого пользователя и служит своего рода небольшим state-хранилищем между сообщениями.

**Поля `user_state`:**

- `user_id` – ID пользователя (такой же, как и в `chat_messages`; является первичным ключом).
- `current_mode` – режим работы, например: `"chat"` или `"documents"` (название `"documents"` используется для режима загрузки базы знаний).
- `updated_at` – временная отметка последнего изменения режима.

Когда пользователь нажимает в Telegram-клиенте кнопку переключения режима (в интерфейсе бота есть меню с кнопками «Чат» и «База»), фронтовой Telegram Bot API генерирует событие `callback_query`. Workflow n8n перехватывает эти события: узел **`Mode set`** выполняет запрос типа POST к REST API Supabase по адресу `/rest/v1/user_state` с заголовком `"Prefer: resolution=merge-duplicates"`. Это означает **upsert-вставку**: если запись для данного `user_id` уже есть, её поле `current_mode` будет обновлено на новое значение, иначе создаётся новая строка. В обоих случаях `updated_at` фиксирует время изменения.

Перед каждым новым сообщением бот проверяет, в каком режиме находится пользователь: узел **`Mode check`** читает текущий режим из `user_state` (SELECT по `user_id`) и дальше по логике workflow либо направляет сообщение в ветку добавления документа (если режим = `"documents"`), либо в ветку чат-обработки вопроса (если режим = `"chat"`). Таким образом, `user_state` позволяет **сохранять выбор пользователя между сообщениями и даже между перезапусками сервиса**. Если бот перезапущен, он «помнит», какой режим был последним у данного пользователя, и продолжает работу в нём по умолчанию.

> *(Замечание: существуют также кнопки "(Clean base)" – по аналогии с очисткой истории, задуман функционал очистки всей базы знаний. В текущей версии они не имеют активной реализации, либо доступны только администратору. Такие операции потребовали бы удаления множества строк из `documents_paragraphs` и, возможно, пересоздания HNSW-индекса.)*

## 6.4 Векторный индекс HNSW для эмбеддингов

Одно из ключевых требований RAG-системы – **быстрый поиск** по векторам среди большого количества документов. В проекте это достигается с помощью расширения **pgvector** и индекса **HNSW** (Hierarchical Navigable Small World) в PostgreSQL. Все эмбеддинги, сохраняемые в поле `documents_paragraphs.embedding`, индексируются для ускорения запросов ближайших соседей.

**Создание индекса:** после установки расширения pgvector была выполнена команда примерно следующего вида:

```sql
CREATE INDEX ON documents_paragraphs
USING hnsw (embedding vector_cosine_ops);
```

Этот индекс настроен для метрики косинусной дистанции (`vector_cosine_ops`), так как эмбеддинги от модели `jina-embeddings-v3` сравниваются по косинусной близости. Алгоритм HNSW строит многослойный граф векторов, достигая гораздо более высокой скорости поиска по сравнению с точным последовательным перебором (особенно на тысячах документов).

HNSW даёт *приближенный* результат – например, может пропустить некоторые соседние точки ради ускорения – но для наших целей это не проблема. Почему? Потому что система реализует **двухэтапный поиск**: сначала HNSW-индекс возвращает относительно широкий пул кандидатов, а затем модель-реранкер (Cross-Encoder) их повторно отбирает и точно сортирует. Таким образом, даже если HNSW пропустит что-то релевантное, второй этап это отфильтрует, и итоговая точность поиска остаётся высокой – практически как при полном переборе, но достигается за доли секунды.

Индекс HNSW строится один раз (или после значительных обновлений данных) и автоматически используется в запросах. Например, при вызове функции поиска (см. далее `search_documents`), планировщик PostgreSQL задействует индекс для операции `ORDER BY dp.embedding <=> query_vector LIMIT K` – тем самым выполняется именно ANN-поиск (Approximate Nearest Neighbors) вместо полного перебора.

В текущей конфигурации индекса используются значения по умолчанию: `m = 16` (максимум связей на слой) и `ef_construction = 64` (размер буфера при построении графа) – этого достаточно для объёма данных в данном проекте. При росте базы знаний параметры можно настроить: например, увеличив `m` до 32 и `ef_search` (параметр запроса) до 100–200, можно добиться ещё большей полноты результатов, оставаясь при этом значительно быстрее традиционного поиска.

Кроме HNSW-индекса, в базе могут быть определены и другие индексы для часто используемых операций. Например, в Supabase запросы к `chat_messages` по `user_id` выполняются очень часто (также операция удаления старых сообщений фильтруется по `user_id`), поэтому целесообразно создать индекс по полю `user_id` в таблице `chat_messages`. Аналогично, в таблице `user_state` первичным ключом является `user_id`, что уже обеспечивает быстрый доступ к состоянию пользователя без необходимости дополнительного индекса.

## 6.5 RPC-функции Supabase: `search_documents` и `insert_and_trim_pairs`

Для удобной интеграции с n8n наиболее тяжёлые и специфичные операции вынесены в SQL-функции, вызовы которых доступны через REST API Supabase (раздел RPC). Проект использует две пользовательские RPC-функции.

### 6.5.1 Функция `search_documents` – ANN-поиск релевантных фрагментов

Функция `search_documents(query_vector vector(768), top_k int)` инкапсулирует весь запрос подобия на стороне БД. Она принимает на вход **вектор запроса** (сгенерированный моделью эмбеддинга для пользовательского вопроса) и желаемый размер выборки `top_k` (например, 30). На выходе функция возвращает таблицу из наиболее релевантных фрагментов, включая поля, нужные для дальнейшей обработки.

Главная часть функции – SQL-запрос с использованием оператора pgvector для сравнения эмбеддингов:

```sql
SELECT dp.id,
       dp.paragraph_text,
       1 - (dp.embedding <=> query_vector) AS score,
       dp.type,
       dp.url,
       dp.file_name,
       dp.paragraph_idx
FROM documents_paragraphs AS dp
WHERE 1 - (dp.embedding <=> query_vector) > 0.2  -- порог по косинусному сходству
ORDER BY dp.embedding <=> query_vector
LIMIT top_k;
```

Здесь оператор `<=>` рассчитывает косинусную дистанцию между двумя векторами. Поскольку для ранжирования нам нужна косинусная **схожесть**, в запросе берётся `1 - distance` – полученное значение `score` лежит в диапазоне [0;1] и тем выше, чем лучше фрагмент соответствует запросу. Условие `WHERE ... > 0.2` отсекает заведомо нерелевантные результаты: фрагменты, схожесть которых с запросом меньше 0.2 (20%), не возвращаются вовсе. Этот эмпирически выбранный порог снижает нагрузку на последующий rerank и LLM, отбрасывая «белый шум».

Сортировка `ORDER BY dp.embedding <=> query_vector` эквивалентна сортировке по возрастанию косинусной дистанции – то есть по убыванию косинусного сходства (самый похожий фрагмент будет первым). Индекс HNSW, описанный в разделе 6.4, как раз и используется PostgreSQL для ускорения такой сортировки с лимитом. В итоге функция `search_documents` возвращает до K лучших фрагментов (например, Top-30), каждый со своим полем `score`.

**Вызов функции:** она зарегистрирована в Supabase и доступна через REST API. Внутри n8n-флоу функция вызывается HTTP-запросом **POST** примерно такого вида:

```http
POST https://<SUPABASE_URL>/rest/v1/rpc/search_documents
{
  "query_vector": [ /* массив из 768 чисел */ ],
  "top_k": 30
}
```

Разумеется, n8n не формирует embedding самостоятельно – вместо этого под капотом работает под-воркфлоу **rag-db-query**: он запрашивает сервис `/embed_late_chunk` с параметром `task = retrieval.query`, получая эмбеддинг вопроса, и сразу передаёт его в `search_documents`. Таким образом, оркестратор (n8n) может одним RPC-вызовом получить нужные данные из базы знаний. Это намного эффективнее, чем выгружать в n8n весь массив эмбеддингов и там фильтровать результаты – СУБД сама выполняет поиск и выдаёт только подходящие записи, минимизируя объем передаваемых данных.

### 6.5.2 Функция `insert_and_trim_pairs` – добавление сообщений чата с ограничением длины

Вторая важная функция – `insert_and_trim_pairs(p_items jsonb, p_keep_pairs int)` – предназначена для пакетного сохранения истории чата с одновременным ограничением её длины. Она принимает два параметра: `p_items` – JSON-массив объектов сообщений (например, пара «вопрос+ответ», либо сразу несколько таких пар), и `p_keep_pairs` – сколько последних пар нужно оставить в истории.

**Логика функции:**

- **Вставка новых сообщений.** Функция в цикле перебирает каждое сообщение из переданного JSON-массива и выполняет `INSERT` в таблицу `chat_messages`. Параметры вставляемой строки берутся из полей JSON-объекта (`user_id`, `message`, `role`, `created_at`). Предполагается, что все сообщения в одном вызове принадлежат одному пользователю – поэтому для оптимизации внутри цикла запоминается идентификатор `the_user` из последнего обработанного объекта (у всей пачки он одинаковый).

- **Ограничение объёма истории.** После вставки новых записей выполняется удаление старых. Значение `keep_count` рассчитывается как `p_keep_pairs * 2` (число сообщений, соответствующее заданному количеству пар, т.е. пар * 2 сообщения). SQL-запрос удаляет из `chat_messages` все сообщения данного пользователя, которые выходят за пределы последних N пар, по дате создания. Проще говоря, остаются только самые свежие `keep_count` записей, а все более старые – удаляются. Это достигается с помощью подзапроса с `ORDER BY created_at DESC OFFSET keep_count`, возвращающего «лишние» ID для удаления.

Ниже приведён упрощённый фрагмент кода функции (на языке PL/pgSQL), иллюстрирующий оба этапа:

```sql
FOR rec IN SELECT * FROM jsonb_array_elements(p_items) LOOP
  INSERT INTO chat_messages(user_id, message, role, created_at)
  VALUES (
    rec->>'user_id',
    rec->>'message',
    rec->>'role',
    (rec->>'created_at')::timestamptz
  );
  the_user := rec->>'user_id';
END LOOP;

DELETE FROM chat_messages
WHERE user_id = the_user
  AND id IN (
    SELECT id
    FROM chat_messages
    WHERE user_id = the_user
    ORDER BY created_at DESC
    OFFSET keep_count
  );
```

В итоге вызов `insert_and_trim_pairs` **одним запросом** добавляет новую пару сообщений в историю и сразу обрезает её до заданного лимита. На практике основной чат-воркфлоу вызывает эту функцию после генерации каждого ответа: перед отправкой ответа пользователю бот вызывает RPC `insert_and_trim_pairs`, передавая JSON с двумя сообщениями (`user` и `assistant`) и параметром количества пар, которые нужно сохранить. Таким образом, в таблицу `chat_messages` добавляются новые записи диалога, а старые автоматически удаляются сверх указанного объёма – история остаётся актуальной и не разрастается бесконтрольно.

---

Следующий документ: **07_deployment.md** – инструкции по развертыванию и описание Docker-образов.
